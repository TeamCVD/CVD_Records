{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "\n",
    "input_csv = pd.read_csv(\"../idata/Unbiased_cwe476_Data_tp.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# from transformers import AutoTokenizer\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
    "\n",
    "# sequence = \"Using a Transformer network is simple\"\n",
    "# tokens = tokenizer.tokenize(sequence)\n",
    "\n",
    "# print(tokens)\n",
    "# ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "\n",
    "# print(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vishagar/miniconda3/envs/huggingface/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Keyword arguments {'add_special_tokens': True, 'padding': 'max_length', 'truncation': True, 'max_length': 512} not recognized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['U', 's', 'i', 'n', 'g', ' ', 'a', ' ', 'T', 'r', 'a', 'n', 's', 'f', 'o', 'r', 'm', 'e', 'r', ' ', 'n', 'e', 't', 'w', 'o', 'r', 'k', ' ', 'i', 's', ' ', 's', 'i', 'm', 'p', 'l', 'e']\n",
      "[85, 115, 105, 110, 103, 32, 97, 32, 84, 114, 97, 110, 115, 102, 111, 114, 109, 101, 114, 32, 110, 101, 116, 119, 111, 114, 107, 32, 105, 115, 32, 115, 105, 109, 112, 108, 101]\n"
     ]
    }
   ],
   "source": [
    "from transformers import CanineTokenizer\n",
    "\n",
    "tokenizer = CanineTokenizer.from_pretrained(\"google/canine-c\")\n",
    "\n",
    "sequence = \"Using a Transformer network is simple\"\n",
    "tokens = tokenizer.tokenize(sequence, add_special_tokens=True, padding=\"max_length\", truncation=True, max_length=512)\n",
    "\n",
    "print(tokens)\n",
    "ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "\n",
    "print(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>CWE-476</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Perl_mro_get_linear_isa(pTHX_ HV *pTHX_Pointe...</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>handlePRERET(FlowInstruction *FlowInstruction...</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GetInetAddr(char *charPointerMarker)\\n\\n{ str...</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>do_redirect(action_list_t *action_list_tPoint...</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gf_af_new(GF_Compositor *GF_CompositorPointer...</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                code  CWE-476  Label\n",
       "0   Perl_mro_get_linear_isa(pTHX_ HV *pTHX_Pointe...     True      1\n",
       "1   handlePRERET(FlowInstruction *FlowInstruction...     True      1\n",
       "2   GetInetAddr(char *charPointerMarker)\\n\\n{ str...     True      1\n",
       "3   do_redirect(action_list_t *action_list_tPoint...     True      1\n",
       "4   gf_af_new(GF_Compositor *GF_CompositorPointer...     True      1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_csv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Perl_mro_get_linear_isa(pTHX_ HV *pTHX_PointerMarker)\n",
      "{\n",
      "    struct mro_meta* structPointerMarker;\n",
      "    AV *AVPointerMarker;\n",
      "\n",
      "    PERL_ARGS_ASSERT_MRO_GET_LINEAR_ISA;\n",
      "    if(!SvOOK(pTHX_PointerMarker))\n",
      "        Perl_croak(aTHX_ \"Can't linearize anonymous symbol table\");\n",
      "\n",
      "    structPointerMarker = HvMROMETA(pTHX_PointerMarker);\n",
      "    if (!structPointerMarker->mro_which)\n",
      "        Perl_croak(aTHX_ \"panic: invalid MRO!\");\n",
      "    AVPointerMarker = structPointerMarker->mro_which->resolve(aTHX_ pTHX_PointerMarker, 0);\n",
      "\n",
      "    if (structPointerMarker->mro_which != &dfs_alg) { \n",
      " SV * const namesv =\n",
      "     (HvENAME(pTHX_PointerMarker)||HvNAME(pTHX_PointerMarker))\n",
      "       ? newSVhek(HvENAME_HEK(pTHX_PointerMarker)\n",
      "     ? HvENAME_HEK(pTHX_PointerMarker)\n",
      "     : HvNAME_HEK(pTHX_PointerMarker))\n",
      "       : NULL;\n",
      "\n",
      " if(namesv && (AvFILLp(AVPointerMarker) == -1 || !sv_eq(*AvARRAY(AVPointerMarker), namesv)))\n",
      " {\n",
      "     AV * const old = AVPointerMarker;\n",
      "     SV **PointerSVPointerMarker;\n",
      "     SV **PointerSVPointerMarker = AvARRAY(old);\n",
      "     SV * const * const oend = PointerSVPointerMarker + AvFILLp(old) + 1;\n",
      "     AVPointerMarker = (AV *)sv_2mortal((SV *)newAV());\n",
      "     av_extend(AVPointerMarker, AvFILLp(AVPointerMarker) = AvFILLp(old)+1);\n",
      "     *AvARRAY(AVPointerMarker) = namesv;\n",
      "     PointerSVPointerMarker = AvARRAY(AVPointerMarker)+1;\n",
      "     while (PointerSVPointerMarker < oend) *PointerSVPointerMarker++ = SvREFCNT_inc(*PointerSVPointerMarker++);\n",
      " }\n",
      " else SvREFCNT_dec(namesv);\n",
      "    }\n",
      "\n",
      "    if (!structPointerMarker->AVPointerMarker) {\n",
      "     HV *const isa_hash = newHV();\n",
      "     \n",
      "     SV *const *PointerSVPointerMarker = AvARRAY(AVPointerMarker);\n",
      "     SV *const *const svp_end = PointerSVPointerMarker + AvFILLp(AVPointerMarker) + 1;\n",
      "     const HEK *HEKPointerMarker = HvENAME_HEK(pTHX_PointerMarker);\n",
      "     if (!HEKPointerMarker) HEKPointerMarker = HvNAME_HEK(pTHX_PointerMarker);\n",
      "\n",
      "     while (PointerSVPointerMarker < svp_end) {\n",
      "  (void) hv_store_ent(isa_hash, *PointerSVPointerMarker++, &PL_sv_undef, 0);\n",
      "     }\n",
      "\n",
      "     (void) hv_common(isa_hash, NULL, HEK_KEY(HEKPointerMarker),\n",
      "        HEK_LEN(HEKPointerMarker), HEK_FLAGS(HEKPointerMarker),\n",
      "        HV_FETCH_ISSTORE, &PL_sv_undef,\n",
      "        HEK_HASH(HEKPointerMarker));\n",
      "     (void) hv_store(isa_hash, \"UNIVERSAL\", 9, &PL_sv_undef, 0);\n",
      "\n",
      "     SvREADONLY_on(isa_hash);\n",
      "\n",
      "     structPointerMarker->AVPointerMarker = isa_hash;\n",
      "    }\n",
      "\n",
      "    return AVPointerMarker;\n",
      "}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sample_text = input_csv['code'][0]\n",
    "print(sample_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' ', 'P', 'e', 'r', 'l', '_', 'm', 'r', 'o', '_', 'g', 'e', 't', '_', 'l', 'i', 'n', 'e', 'a', 'r', '_', 'i', 's', 'a', '(', 'p', 'T', 'H', 'X', '_', ' ', 'H', 'V', ' ', '*', 'p', 'T', 'H', 'X', '_', 'P', 'o', 'i', 'n', 't', 'e', 'r', 'M', 'a', 'r', 'k', 'e', 'r', ')', '\\n', '{', '\\n', ' ', ' ', ' ', ' ', 's', 't', 'r', 'u', 'c', 't', ' ', 'm', 'r', 'o', '_', 'm', 'e', 't', 'a', '*', ' ', 's', 't', 'r', 'u', 'c', 't', 'P', 'o', 'i', 'n', 't', 'e', 'r', 'M', 'a', 'r', 'k', 'e', 'r', ';', '\\n', ' ', ' ', ' ', ' ', 'A', 'V', ' ', '*', 'A', 'V', 'P', 'o', 'i', 'n', 't', 'e', 'r', 'M', 'a', 'r', 'k', 'e', 'r', ';', '\\n', '\\n', ' ', ' ', ' ', ' ', 'P', 'E', 'R', 'L', '_', 'A', 'R', 'G', 'S', '_', 'A', 'S', 'S', 'E', 'R', 'T', '_', 'M', 'R', 'O', '_', 'G', 'E', 'T', '_', 'L', 'I', 'N', 'E', 'A', 'R', '_', 'I', 'S', 'A', ';', '\\n', ' ', ' ', ' ', ' ', 'i', 'f', '(', '!', 'S', 'v', 'O', 'O', 'K', '(', 'p', 'T', 'H', 'X', '_', 'P', 'o', 'i', 'n', 't', 'e', 'r', 'M', 'a', 'r', 'k', 'e', 'r', ')', ')', '\\n', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', 'P', 'e', 'r', 'l', '_', 'c', 'r', 'o', 'a', 'k', '(', 'a', 'T', 'H', 'X', '_', ' ', '\"', 'C', 'a', 'n', \"'\", 't', ' ', 'l', 'i', 'n', 'e', 'a', 'r', 'i', 'z', 'e', ' ', 'a', 'n', 'o', 'n', 'y', 'm', 'o', 'u', 's', ' ', 's', 'y', 'm', 'b', 'o', 'l', ' ', 't', 'a', 'b', 'l', 'e', '\"', ')', ';', '\\n', '\\n', ' ', ' ', ' ', ' ', 's', 't', 'r', 'u', 'c', 't', 'P', 'o', 'i', 'n', 't', 'e', 'r', 'M', 'a', 'r', 'k', 'e', 'r', ' ', '=', ' ', 'H', 'v', 'M', 'R', 'O', 'M', 'E', 'T', 'A', '(', 'p', 'T', 'H', 'X', '_', 'P', 'o', 'i', 'n', 't', 'e', 'r', 'M', 'a', 'r', 'k', 'e', 'r', ')', ';', '\\n', ' ', ' ', ' ', ' ', 'i', 'f', ' ', '(', '!', 's', 't', 'r', 'u', 'c', 't', 'P', 'o', 'i', 'n', 't', 'e', 'r', 'M', 'a', 'r', 'k', 'e', 'r', '-', '>', 'm', 'r', 'o', '_', 'w', 'h', 'i', 'c', 'h', ')', '\\n', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', 'P', 'e', 'r', 'l', '_', 'c', 'r', 'o', 'a', 'k', '(', 'a', 'T', 'H', 'X', '_', ' ', '\"', 'p', 'a', 'n', 'i', 'c', ':', ' ', 'i', 'n', 'v', 'a', 'l', 'i', 'd', ' ', 'M', 'R', 'O', '!', '\"', ')', ';', '\\n', ' ', ' ', ' ', ' ', 'A', 'V', 'P', 'o', 'i', 'n', 't', 'e', 'r', 'M', 'a', 'r', 'k', 'e', 'r', ' ', '=', ' ', 's', 't', 'r', 'u', 'c', 't', 'P', 'o', 'i', 'n', 't', 'e', 'r', 'M', 'a', 'r', 'k', 'e', 'r', '-', '>', 'm', 'r', 'o', '_', 'w', 'h', 'i', 'c', 'h', '-', '>', 'r', 'e', 's', 'o', 'l', 'v', 'e', '(', 'a', 'T', 'H', 'X', '_', ' ', 'p', 'T', 'H', 'X', '_', 'P', 'o', 'i', 'n', 't', 'e', 'r', 'M', 'a', 'r', 'k', 'e', 'r', ',', ' ', '0', ')', ';', '\\n', '\\n', ' ', ' ', ' ', ' ', 'i', 'f', ' ', '(', 's', 't', 'r', 'u', 'c', 't', 'P', 'o', 'i', 'n', 't', 'e', 'r', 'M', 'a', 'r', 'k', 'e', 'r', '-', '>', 'm', 'r', 'o', '_', 'w', 'h', 'i', 'c', 'h', ' ', '!', '=', ' ', '&', 'd', 'f', 's', '_', 'a', 'l', 'g', ')', ' ', '{', ' ', '\\n', ' ', 'S', 'V', ' ', '*', ' ', 'c', 'o', 'n', 's', 't', ' ', 'n', 'a', 'm', 'e', 's', 'v', ' ', '=', '\\n', ' ', ' ', ' ', ' ', ' ', '(', 'H', 'v', 'E', 'N', 'A', 'M', 'E', '(', 'p', 'T', 'H', 'X', '_', 'P', 'o', 'i', 'n', 't', 'e', 'r', 'M', 'a', 'r', 'k', 'e', 'r', ')', '|', '|', 'H', 'v', 'N', 'A', 'M', 'E', '(', 'p', 'T', 'H', 'X', '_', 'P', 'o', 'i', 'n', 't', 'e', 'r', 'M', 'a', 'r', 'k', 'e', 'r', ')', ')', '\\n', ' ', ' ', ' ', ' ', ' ', ' ', ' ', '?', ' ', 'n', 'e', 'w', 'S', 'V', 'h', 'e', 'k', '(', 'H', 'v', 'E', 'N', 'A', 'M', 'E', '_', 'H', 'E', 'K', '(', 'p', 'T', 'H', 'X', '_', 'P', 'o', 'i', 'n', 't', 'e', 'r', 'M', 'a', 'r', 'k', 'e', 'r', ')', '\\n', ' ', ' ', ' ', ' ', ' ', '?', ' ', 'H', 'v', 'E', 'N', 'A', 'M', 'E', '_', 'H', 'E', 'K', '(', 'p', 'T', 'H', 'X', '_', 'P', 'o', 'i', 'n', 't', 'e', 'r', 'M', 'a', 'r', 'k', 'e', 'r', ')', '\\n', ' ', ' ', ' ', ' ', ' ', ':', ' ', 'H', 'v', 'N', 'A', 'M', 'E', '_', 'H', 'E', 'K', '(', 'p', 'T', 'H', 'X', '_', 'P', 'o', 'i', 'n', 't', 'e', 'r', 'M', 'a', 'r', 'k', 'e', 'r', ')', ')', '\\n', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ':', ' ', 'N', 'U', 'L', 'L', ';', '\\n', '\\n', ' ', 'i', 'f', '(', 'n', 'a', 'm', 'e', 's', 'v', ' ', '&', '&', ' ', '(', 'A', 'v', 'F', 'I', 'L', 'L', 'p', '(', 'A', 'V', 'P', 'o', 'i', 'n', 't', 'e', 'r', 'M', 'a', 'r', 'k', 'e', 'r', ')', ' ', '=', '=', ' ', '-', '1', ' ', '|', '|', ' ', '!', 's', 'v', '_', 'e', 'q', '(', '*', 'A', 'v', 'A', 'R', 'R', 'A', 'Y', '(', 'A', 'V', 'P', 'o', 'i', 'n', 't', 'e', 'r', 'M', 'a', 'r', 'k', 'e', 'r', ')', ',', ' ', 'n', 'a', 'm', 'e', 's', 'v', ')', ')', ')', '\\n', ' ', '{', '\\n', ' ', ' ', ' ', ' ', ' ', 'A', 'V', ' ', '*', ' ', 'c', 'o', 'n', 's', 't', ' ', 'o', 'l', 'd', ' ', '=', ' ', 'A', 'V', 'P', 'o', 'i', 'n', 't', 'e', 'r', 'M', 'a', 'r', 'k', 'e', 'r', ';', '\\n', ' ', ' ', ' ', ' ', ' ', 'S', 'V', ' ', '*', '*', 'P', 'o', 'i', 'n', 't', 'e', 'r', 'S', 'V', 'P', 'o', 'i', 'n', 't', 'e', 'r', 'M', 'a', 'r', 'k', 'e', 'r', ';', '\\n', ' ', ' ', ' ', ' ', ' ', 'S', 'V', ' ', '*', '*', 'P', 'o', 'i', 'n', 't', 'e', 'r', 'S', 'V', 'P', 'o', 'i', 'n', 't', 'e', 'r', 'M', 'a', 'r', 'k', 'e', 'r', ' ', '=', ' ', 'A', 'v', 'A', 'R', 'R', 'A', 'Y', '(', 'o', 'l', 'd', ')', ';', '\\n', ' ', ' ', ' ', ' ', ' ', 'S', 'V', ' ', '*', ' ', 'c', 'o', 'n', 's', 't', ' ', '*', ' ', 'c', 'o', 'n', 's', 't', ' ', 'o', 'e', 'n', 'd', ' ', '=', ' ', 'P', 'o', 'i', 'n', 't', 'e', 'r', 'S', 'V', 'P', 'o', 'i', 'n', 't', 'e', 'r', 'M', 'a', 'r', 'k', 'e', 'r', ' ', '+', ' ', 'A', 'v', 'F', 'I', 'L', 'L', 'p', '(', 'o', 'l', 'd', ')', ' ', '+', ' ', '1', ';', '\\n', ' ', ' ', ' ', ' ', ' ', 'A', 'V', 'P', 'o', 'i', 'n', 't', 'e', 'r', 'M', 'a', 'r', 'k', 'e', 'r', ' ', '=', ' ', '(', 'A', 'V', ' ', '*', ')', 's', 'v', '_', '2', 'm', 'o', 'r', 't', 'a', 'l', '(', '(', 'S', 'V', ' ', '*', ')', 'n', 'e', 'w', 'A', 'V', '(', ')', ')', ';', '\\n', ' ', ' ', ' ', ' ', ' ', 'a', 'v', '_', 'e', 'x', 't', 'e', 'n', 'd', '(', 'A', 'V', 'P', 'o', 'i', 'n', 't', 'e', 'r', 'M', 'a', 'r', 'k', 'e', 'r', ',', ' ', 'A', 'v', 'F', 'I', 'L', 'L', 'p', '(', 'A', 'V', 'P', 'o', 'i', 'n', 't', 'e', 'r', 'M', 'a', 'r', 'k', 'e', 'r', ')', ' ', '=', ' ', 'A', 'v', 'F', 'I', 'L', 'L', 'p', '(', 'o', 'l', 'd', ')', '+', '1', ')', ';', '\\n', ' ', ' ', ' ', ' ', ' ', '*', 'A', 'v', 'A', 'R', 'R', 'A', 'Y', '(', 'A', 'V', 'P', 'o', 'i', 'n', 't', 'e', 'r', 'M', 'a', 'r', 'k', 'e', 'r', ')', ' ', '=', ' ', 'n', 'a', 'm', 'e', 's', 'v', ';', '\\n', ' ', ' ', ' ', ' ', ' ', 'P', 'o', 'i', 'n', 't', 'e', 'r', 'S', 'V', 'P', 'o', 'i', 'n', 't', 'e', 'r', 'M', 'a', 'r', 'k', 'e', 'r', ' ', '=', ' ', 'A', 'v', 'A', 'R', 'R', 'A', 'Y', '(', 'A', 'V', 'P', 'o', 'i', 'n', 't', 'e', 'r', 'M', 'a', 'r', 'k', 'e', 'r', ')', '+', '1', ';', '\\n', ' ', ' ', ' ', ' ', ' ', 'w', 'h', 'i', 'l', 'e', ' ', '(', 'P', 'o', 'i', 'n', 't', 'e', 'r', 'S', 'V', 'P', 'o', 'i', 'n', 't', 'e', 'r', 'M', 'a', 'r', 'k', 'e', 'r', ' ', '<', ' ', 'o', 'e', 'n', 'd', ')', ' ', '*', 'P', 'o', 'i', 'n', 't', 'e', 'r', 'S', 'V', 'P', 'o', 'i', 'n', 't', 'e', 'r', 'M', 'a', 'r', 'k', 'e', 'r', '+', '+', ' ', '=', ' ', 'S', 'v', 'R', 'E', 'F', 'C', 'N', 'T', '_', 'i', 'n', 'c', '(', '*', 'P', 'o', 'i', 'n', 't', 'e', 'r', 'S', 'V', 'P', 'o', 'i', 'n', 't', 'e', 'r', 'M', 'a', 'r', 'k', 'e', 'r', '+', '+', ')', ';', '\\n', ' ', '}', '\\n', ' ', 'e', 'l', 's', 'e', ' ', 'S', 'v', 'R', 'E', 'F', 'C', 'N', 'T', '_', 'd', 'e', 'c', '(', 'n', 'a', 'm', 'e', 's', 'v', ')', ';', '\\n', ' ', ' ', ' ', ' ', '}', '\\n', '\\n', ' ', ' ', ' ', ' ', 'i', 'f', ' ', '(', '!', 's', 't', 'r', 'u', 'c', 't', 'P', 'o', 'i', 'n', 't', 'e', 'r', 'M', 'a', 'r', 'k', 'e', 'r', '-', '>', 'A', 'V', 'P', 'o', 'i', 'n', 't', 'e', 'r', 'M', 'a', 'r', 'k', 'e', 'r', ')', ' ', '{', '\\n', ' ', ' ', ' ', ' ', ' ', 'H', 'V', ' ', '*', 'c', 'o', 'n', 's', 't', ' ', 'i', 's', 'a', '_', 'h', 'a', 's', 'h', ' ', '=', ' ', 'n', 'e', 'w', 'H', 'V', '(', ')', ';', '\\n', ' ', ' ', ' ', ' ', ' ', '\\n', ' ', ' ', ' ', ' ', ' ', 'S', 'V', ' ', '*', 'c', 'o', 'n', 's', 't', ' ', '*', 'P', 'o', 'i', 'n', 't', 'e', 'r', 'S', 'V', 'P', 'o', 'i', 'n', 't', 'e', 'r', 'M', 'a', 'r', 'k', 'e', 'r', ' ', '=', ' ', 'A', 'v', 'A', 'R', 'R', 'A', 'Y', '(', 'A', 'V', 'P', 'o', 'i', 'n', 't', 'e', 'r', 'M', 'a', 'r', 'k', 'e', 'r', ')', ';', '\\n', ' ', ' ', ' ', ' ', ' ', 'S', 'V', ' ', '*', 'c', 'o', 'n', 's', 't', ' ', '*', 'c', 'o', 'n', 's', 't', ' ', 's', 'v', 'p', '_', 'e', 'n', 'd', ' ', '=', ' ', 'P', 'o', 'i', 'n', 't', 'e', 'r', 'S', 'V', 'P', 'o', 'i', 'n', 't', 'e', 'r', 'M', 'a', 'r', 'k', 'e', 'r', ' ', '+', ' ', 'A', 'v', 'F', 'I', 'L', 'L', 'p', '(', 'A', 'V', 'P', 'o', 'i', 'n', 't', 'e', 'r', 'M', 'a', 'r', 'k', 'e', 'r', ')', ' ', '+', ' ', '1', ';', '\\n', ' ', ' ', ' ', ' ', ' ', 'c', 'o', 'n', 's', 't', ' ', 'H', 'E', 'K', ' ', '*', 'H', 'E', 'K', 'P', 'o', 'i', 'n', 't', 'e', 'r', 'M', 'a', 'r', 'k', 'e', 'r', ' ', '=', ' ', 'H', 'v', 'E', 'N', 'A', 'M', 'E', '_', 'H', 'E', 'K', '(', 'p', 'T', 'H', 'X', '_', 'P', 'o', 'i', 'n', 't', 'e', 'r', 'M', 'a', 'r', 'k', 'e', 'r', ')', ';', '\\n', ' ', ' ', ' ', ' ', ' ', 'i', 'f', ' ', '(', '!', 'H', 'E', 'K', 'P', 'o', 'i', 'n', 't', 'e', 'r', 'M', 'a', 'r', 'k', 'e', 'r', ')', ' ', 'H', 'E', 'K', 'P', 'o', 'i', 'n', 't', 'e', 'r', 'M', 'a', 'r', 'k', 'e', 'r', ' ', '=', ' ', 'H', 'v', 'N', 'A', 'M', 'E', '_', 'H', 'E', 'K', '(', 'p', 'T', 'H', 'X', '_', 'P', 'o', 'i', 'n', 't', 'e', 'r', 'M', 'a', 'r', 'k', 'e', 'r', ')', ';', '\\n', '\\n', ' ', ' ', ' ', ' ', ' ', 'w', 'h', 'i', 'l', 'e', ' ', '(', 'P', 'o', 'i', 'n', 't', 'e', 'r', 'S', 'V', 'P', 'o', 'i', 'n', 't', 'e', 'r', 'M', 'a', 'r', 'k', 'e', 'r', ' ', '<', ' ', 's', 'v', 'p', '_', 'e', 'n', 'd', ')', ' ', '{', '\\n', ' ', ' ', '(', 'v', 'o', 'i', 'd', ')', ' ', 'h', 'v', '_', 's', 't', 'o', 'r', 'e', '_', 'e', 'n', 't', '(', 'i', 's', 'a', '_', 'h', 'a', 's', 'h', ',', ' ', '*', 'P', 'o', 'i', 'n', 't', 'e', 'r', 'S', 'V', 'P', 'o', 'i', 'n', 't', 'e', 'r', 'M', 'a', 'r', 'k', 'e', 'r', '+', '+', ',', ' ', '&', 'P', 'L', '_', 's', 'v', '_', 'u', 'n', 'd', 'e', 'f', ',', ' ', '0', ')', ';', '\\n', ' ', ' ', ' ', ' ', ' ', '}', '\\n', '\\n', ' ', ' ', ' ', ' ', ' ', '(', 'v', 'o', 'i', 'd', ')', ' ', 'h', 'v', '_', 'c', 'o', 'm', 'm', 'o', 'n', '(', 'i', 's', 'a', '_', 'h', 'a', 's', 'h', ',', ' ', 'N', 'U', 'L', 'L', ',', ' ', 'H', 'E', 'K', '_', 'K', 'E', 'Y', '(', 'H', 'E', 'K', 'P', 'o', 'i', 'n', 't', 'e', 'r', 'M', 'a', 'r', 'k', 'e', 'r', ')', ',', '\\n', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', 'H', 'E', 'K', '_', 'L', 'E', 'N', '(', 'H', 'E', 'K', 'P', 'o', 'i', 'n', 't', 'e', 'r', 'M', 'a', 'r', 'k', 'e', 'r', ')', ',', ' ', 'H', 'E', 'K', '_', 'F', 'L', 'A', 'G', 'S', '(', 'H', 'E', 'K', 'P', 'o', 'i', 'n', 't', 'e', 'r', 'M', 'a', 'r', 'k', 'e', 'r', ')', ',', '\\n', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', 'H', 'V', '_', 'F', 'E', 'T', 'C', 'H', '_', 'I', 'S', 'S', 'T', 'O', 'R', 'E', ',', ' ', '&', 'P', 'L', '_', 's', 'v', '_', 'u', 'n', 'd', 'e', 'f', ',', '\\n', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', 'H', 'E', 'K', '_', 'H', 'A', 'S', 'H', '(', 'H', 'E', 'K', 'P', 'o', 'i', 'n', 't', 'e', 'r', 'M', 'a', 'r', 'k', 'e', 'r', ')', ')', ';', '\\n', ' ', ' ', ' ', ' ', ' ', '(', 'v', 'o', 'i', 'd', ')', ' ', 'h', 'v', '_', 's', 't', 'o', 'r', 'e', '(', 'i', 's', 'a', '_', 'h', 'a', 's', 'h', ',', ' ', '\"', 'U', 'N', 'I', 'V', 'E', 'R', 'S', 'A', 'L', '\"', ',', ' ', '9', ',', ' ', '&', 'P', 'L', '_', 's', 'v', '_', 'u', 'n', 'd', 'e', 'f', ',', ' ', '0', ')', ';', '\\n', '\\n', ' ', ' ', ' ', ' ', ' ', 'S', 'v', 'R', 'E', 'A', 'D', 'O', 'N', 'L', 'Y', '_', 'o', 'n', '(', 'i', 's', 'a', '_', 'h', 'a', 's', 'h', ')', ';', '\\n', '\\n', ' ', ' ', ' ', ' ', ' ', 's', 't', 'r', 'u', 'c', 't', 'P', 'o', 'i', 'n', 't', 'e', 'r', 'M', 'a', 'r', 'k', 'e', 'r', '-', '>', 'A', 'V', 'P', 'o', 'i', 'n', 't', 'e', 'r', 'M', 'a', 'r', 'k', 'e', 'r', ' ', '=', ' ', 'i', 's', 'a', '_', 'h', 'a', 's', 'h', ';', '\\n', ' ', ' ', ' ', ' ', '}', '\\n', '\\n', ' ', ' ', ' ', ' ', 'r', 'e', 't', 'u', 'r', 'n', ' ', 'A', 'V', 'P', 'o', 'i', 'n', 't', 'e', 'r', 'M', 'a', 'r', 'k', 'e', 'r', ';', '\\n', '}', '\\n', '\\n']\n",
      "[32, 80, 101, 114, 108, 95, 109, 114, 111, 95, 103, 101, 116, 95, 108, 105, 110, 101, 97, 114, 95, 105, 115, 97, 40, 112, 84, 72, 88, 95, 32, 72, 86, 32, 42, 112, 84, 72, 88, 95, 80, 111, 105, 110, 116, 101, 114, 77, 97, 114, 107, 101, 114, 41, 10, 123, 10, 32, 32, 32, 32, 115, 116, 114, 117, 99, 116, 32, 109, 114, 111, 95, 109, 101, 116, 97, 42, 32, 115, 116, 114, 117, 99, 116, 80, 111, 105, 110, 116, 101, 114, 77, 97, 114, 107, 101, 114, 59, 10, 32, 32, 32, 32, 65, 86, 32, 42, 65, 86, 80, 111, 105, 110, 116, 101, 114, 77, 97, 114, 107, 101, 114, 59, 10, 10, 32, 32, 32, 32, 80, 69, 82, 76, 95, 65, 82, 71, 83, 95, 65, 83, 83, 69, 82, 84, 95, 77, 82, 79, 95, 71, 69, 84, 95, 76, 73, 78, 69, 65, 82, 95, 73, 83, 65, 59, 10, 32, 32, 32, 32, 105, 102, 40, 33, 83, 118, 79, 79, 75, 40, 112, 84, 72, 88, 95, 80, 111, 105, 110, 116, 101, 114, 77, 97, 114, 107, 101, 114, 41, 41, 10, 32, 32, 32, 32, 32, 32, 32, 32, 80, 101, 114, 108, 95, 99, 114, 111, 97, 107, 40, 97, 84, 72, 88, 95, 32, 34, 67, 97, 110, 39, 116, 32, 108, 105, 110, 101, 97, 114, 105, 122, 101, 32, 97, 110, 111, 110, 121, 109, 111, 117, 115, 32, 115, 121, 109, 98, 111, 108, 32, 116, 97, 98, 108, 101, 34, 41, 59, 10, 10, 32, 32, 32, 32, 115, 116, 114, 117, 99, 116, 80, 111, 105, 110, 116, 101, 114, 77, 97, 114, 107, 101, 114, 32, 61, 32, 72, 118, 77, 82, 79, 77, 69, 84, 65, 40, 112, 84, 72, 88, 95, 80, 111, 105, 110, 116, 101, 114, 77, 97, 114, 107, 101, 114, 41, 59, 10, 32, 32, 32, 32, 105, 102, 32, 40, 33, 115, 116, 114, 117, 99, 116, 80, 111, 105, 110, 116, 101, 114, 77, 97, 114, 107, 101, 114, 45, 62, 109, 114, 111, 95, 119, 104, 105, 99, 104, 41, 10, 32, 32, 32, 32, 32, 32, 32, 32, 80, 101, 114, 108, 95, 99, 114, 111, 97, 107, 40, 97, 84, 72, 88, 95, 32, 34, 112, 97, 110, 105, 99, 58, 32, 105, 110, 118, 97, 108, 105, 100, 32, 77, 82, 79, 33, 34, 41, 59, 10, 32, 32, 32, 32, 65, 86, 80, 111, 105, 110, 116, 101, 114, 77, 97, 114, 107, 101, 114, 32, 61, 32, 115, 116, 114, 117, 99, 116, 80, 111, 105, 110, 116, 101, 114, 77, 97, 114, 107, 101, 114, 45, 62, 109, 114, 111, 95, 119, 104, 105, 99, 104, 45, 62, 114, 101, 115, 111, 108, 118, 101, 40, 97, 84, 72, 88, 95, 32, 112, 84, 72, 88, 95, 80, 111, 105, 110, 116, 101, 114, 77, 97, 114, 107, 101, 114, 44, 32, 48, 41, 59, 10, 10, 32, 32, 32, 32, 105, 102, 32, 40, 115, 116, 114, 117, 99, 116, 80, 111, 105, 110, 116, 101, 114, 77, 97, 114, 107, 101, 114, 45, 62, 109, 114, 111, 95, 119, 104, 105, 99, 104, 32, 33, 61, 32, 38, 100, 102, 115, 95, 97, 108, 103, 41, 32, 123, 32, 10, 32, 83, 86, 32, 42, 32, 99, 111, 110, 115, 116, 32, 110, 97, 109, 101, 115, 118, 32, 61, 10, 32, 32, 32, 32, 32, 40, 72, 118, 69, 78, 65, 77, 69, 40, 112, 84, 72, 88, 95, 80, 111, 105, 110, 116, 101, 114, 77, 97, 114, 107, 101, 114, 41, 124, 124, 72, 118, 78, 65, 77, 69, 40, 112, 84, 72, 88, 95, 80, 111, 105, 110, 116, 101, 114, 77, 97, 114, 107, 101, 114, 41, 41, 10, 32, 32, 32, 32, 32, 32, 32, 63, 32, 110, 101, 119, 83, 86, 104, 101, 107, 40, 72, 118, 69, 78, 65, 77, 69, 95, 72, 69, 75, 40, 112, 84, 72, 88, 95, 80, 111, 105, 110, 116, 101, 114, 77, 97, 114, 107, 101, 114, 41, 10, 32, 32, 32, 32, 32, 63, 32, 72, 118, 69, 78, 65, 77, 69, 95, 72, 69, 75, 40, 112, 84, 72, 88, 95, 80, 111, 105, 110, 116, 101, 114, 77, 97, 114, 107, 101, 114, 41, 10, 32, 32, 32, 32, 32, 58, 32, 72, 118, 78, 65, 77, 69, 95, 72, 69, 75, 40, 112, 84, 72, 88, 95, 80, 111, 105, 110, 116, 101, 114, 77, 97, 114, 107, 101, 114, 41, 41, 10, 32, 32, 32, 32, 32, 32, 32, 58, 32, 78, 85, 76, 76, 59, 10, 10, 32, 105, 102, 40, 110, 97, 109, 101, 115, 118, 32, 38, 38, 32, 40, 65, 118, 70, 73, 76, 76, 112, 40, 65, 86, 80, 111, 105, 110, 116, 101, 114, 77, 97, 114, 107, 101, 114, 41, 32, 61, 61, 32, 45, 49, 32, 124, 124, 32, 33, 115, 118, 95, 101, 113, 40, 42, 65, 118, 65, 82, 82, 65, 89, 40, 65, 86, 80, 111, 105, 110, 116, 101, 114, 77, 97, 114, 107, 101, 114, 41, 44, 32, 110, 97, 109, 101, 115, 118, 41, 41, 41, 10, 32, 123, 10, 32, 32, 32, 32, 32, 65, 86, 32, 42, 32, 99, 111, 110, 115, 116, 32, 111, 108, 100, 32, 61, 32, 65, 86, 80, 111, 105, 110, 116, 101, 114, 77, 97, 114, 107, 101, 114, 59, 10, 32, 32, 32, 32, 32, 83, 86, 32, 42, 42, 80, 111, 105, 110, 116, 101, 114, 83, 86, 80, 111, 105, 110, 116, 101, 114, 77, 97, 114, 107, 101, 114, 59, 10, 32, 32, 32, 32, 32, 83, 86, 32, 42, 42, 80, 111, 105, 110, 116, 101, 114, 83, 86, 80, 111, 105, 110, 116, 101, 114, 77, 97, 114, 107, 101, 114, 32, 61, 32, 65, 118, 65, 82, 82, 65, 89, 40, 111, 108, 100, 41, 59, 10, 32, 32, 32, 32, 32, 83, 86, 32, 42, 32, 99, 111, 110, 115, 116, 32, 42, 32, 99, 111, 110, 115, 116, 32, 111, 101, 110, 100, 32, 61, 32, 80, 111, 105, 110, 116, 101, 114, 83, 86, 80, 111, 105, 110, 116, 101, 114, 77, 97, 114, 107, 101, 114, 32, 43, 32, 65, 118, 70, 73, 76, 76, 112, 40, 111, 108, 100, 41, 32, 43, 32, 49, 59, 10, 32, 32, 32, 32, 32, 65, 86, 80, 111, 105, 110, 116, 101, 114, 77, 97, 114, 107, 101, 114, 32, 61, 32, 40, 65, 86, 32, 42, 41, 115, 118, 95, 50, 109, 111, 114, 116, 97, 108, 40, 40, 83, 86, 32, 42, 41, 110, 101, 119, 65, 86, 40, 41, 41, 59, 10, 32, 32, 32, 32, 32, 97, 118, 95, 101, 120, 116, 101, 110, 100, 40, 65, 86, 80, 111, 105, 110, 116, 101, 114, 77, 97, 114, 107, 101, 114, 44, 32, 65, 118, 70, 73, 76, 76, 112, 40, 65, 86, 80, 111, 105, 110, 116, 101, 114, 77, 97, 114, 107, 101, 114, 41, 32, 61, 32, 65, 118, 70, 73, 76, 76, 112, 40, 111, 108, 100, 41, 43, 49, 41, 59, 10, 32, 32, 32, 32, 32, 42, 65, 118, 65, 82, 82, 65, 89, 40, 65, 86, 80, 111, 105, 110, 116, 101, 114, 77, 97, 114, 107, 101, 114, 41, 32, 61, 32, 110, 97, 109, 101, 115, 118, 59, 10, 32, 32, 32, 32, 32, 80, 111, 105, 110, 116, 101, 114, 83, 86, 80, 111, 105, 110, 116, 101, 114, 77, 97, 114, 107, 101, 114, 32, 61, 32, 65, 118, 65, 82, 82, 65, 89, 40, 65, 86, 80, 111, 105, 110, 116, 101, 114, 77, 97, 114, 107, 101, 114, 41, 43, 49, 59, 10, 32, 32, 32, 32, 32, 119, 104, 105, 108, 101, 32, 40, 80, 111, 105, 110, 116, 101, 114, 83, 86, 80, 111, 105, 110, 116, 101, 114, 77, 97, 114, 107, 101, 114, 32, 60, 32, 111, 101, 110, 100, 41, 32, 42, 80, 111, 105, 110, 116, 101, 114, 83, 86, 80, 111, 105, 110, 116, 101, 114, 77, 97, 114, 107, 101, 114, 43, 43, 32, 61, 32, 83, 118, 82, 69, 70, 67, 78, 84, 95, 105, 110, 99, 40, 42, 80, 111, 105, 110, 116, 101, 114, 83, 86, 80, 111, 105, 110, 116, 101, 114, 77, 97, 114, 107, 101, 114, 43, 43, 41, 59, 10, 32, 125, 10, 32, 101, 108, 115, 101, 32, 83, 118, 82, 69, 70, 67, 78, 84, 95, 100, 101, 99, 40, 110, 97, 109, 101, 115, 118, 41, 59, 10, 32, 32, 32, 32, 125, 10, 10, 32, 32, 32, 32, 105, 102, 32, 40, 33, 115, 116, 114, 117, 99, 116, 80, 111, 105, 110, 116, 101, 114, 77, 97, 114, 107, 101, 114, 45, 62, 65, 86, 80, 111, 105, 110, 116, 101, 114, 77, 97, 114, 107, 101, 114, 41, 32, 123, 10, 32, 32, 32, 32, 32, 72, 86, 32, 42, 99, 111, 110, 115, 116, 32, 105, 115, 97, 95, 104, 97, 115, 104, 32, 61, 32, 110, 101, 119, 72, 86, 40, 41, 59, 10, 32, 32, 32, 32, 32, 10, 32, 32, 32, 32, 32, 83, 86, 32, 42, 99, 111, 110, 115, 116, 32, 42, 80, 111, 105, 110, 116, 101, 114, 83, 86, 80, 111, 105, 110, 116, 101, 114, 77, 97, 114, 107, 101, 114, 32, 61, 32, 65, 118, 65, 82, 82, 65, 89, 40, 65, 86, 80, 111, 105, 110, 116, 101, 114, 77, 97, 114, 107, 101, 114, 41, 59, 10, 32, 32, 32, 32, 32, 83, 86, 32, 42, 99, 111, 110, 115, 116, 32, 42, 99, 111, 110, 115, 116, 32, 115, 118, 112, 95, 101, 110, 100, 32, 61, 32, 80, 111, 105, 110, 116, 101, 114, 83, 86, 80, 111, 105, 110, 116, 101, 114, 77, 97, 114, 107, 101, 114, 32, 43, 32, 65, 118, 70, 73, 76, 76, 112, 40, 65, 86, 80, 111, 105, 110, 116, 101, 114, 77, 97, 114, 107, 101, 114, 41, 32, 43, 32, 49, 59, 10, 32, 32, 32, 32, 32, 99, 111, 110, 115, 116, 32, 72, 69, 75, 32, 42, 72, 69, 75, 80, 111, 105, 110, 116, 101, 114, 77, 97, 114, 107, 101, 114, 32, 61, 32, 72, 118, 69, 78, 65, 77, 69, 95, 72, 69, 75, 40, 112, 84, 72, 88, 95, 80, 111, 105, 110, 116, 101, 114, 77, 97, 114, 107, 101, 114, 41, 59, 10, 32, 32, 32, 32, 32, 105, 102, 32, 40, 33, 72, 69, 75, 80, 111, 105, 110, 116, 101, 114, 77, 97, 114, 107, 101, 114, 41, 32, 72, 69, 75, 80, 111, 105, 110, 116, 101, 114, 77, 97, 114, 107, 101, 114, 32, 61, 32, 72, 118, 78, 65, 77, 69, 95, 72, 69, 75, 40, 112, 84, 72, 88, 95, 80, 111, 105, 110, 116, 101, 114, 77, 97, 114, 107, 101, 114, 41, 59, 10, 10, 32, 32, 32, 32, 32, 119, 104, 105, 108, 101, 32, 40, 80, 111, 105, 110, 116, 101, 114, 83, 86, 80, 111, 105, 110, 116, 101, 114, 77, 97, 114, 107, 101, 114, 32, 60, 32, 115, 118, 112, 95, 101, 110, 100, 41, 32, 123, 10, 32, 32, 40, 118, 111, 105, 100, 41, 32, 104, 118, 95, 115, 116, 111, 114, 101, 95, 101, 110, 116, 40, 105, 115, 97, 95, 104, 97, 115, 104, 44, 32, 42, 80, 111, 105, 110, 116, 101, 114, 83, 86, 80, 111, 105, 110, 116, 101, 114, 77, 97, 114, 107, 101, 114, 43, 43, 44, 32, 38, 80, 76, 95, 115, 118, 95, 117, 110, 100, 101, 102, 44, 32, 48, 41, 59, 10, 32, 32, 32, 32, 32, 125, 10, 10, 32, 32, 32, 32, 32, 40, 118, 111, 105, 100, 41, 32, 104, 118, 95, 99, 111, 109, 109, 111, 110, 40, 105, 115, 97, 95, 104, 97, 115, 104, 44, 32, 78, 85, 76, 76, 44, 32, 72, 69, 75, 95, 75, 69, 89, 40, 72, 69, 75, 80, 111, 105, 110, 116, 101, 114, 77, 97, 114, 107, 101, 114, 41, 44, 10, 32, 32, 32, 32, 32, 32, 32, 32, 72, 69, 75, 95, 76, 69, 78, 40, 72, 69, 75, 80, 111, 105, 110, 116, 101, 114, 77, 97, 114, 107, 101, 114, 41, 44, 32, 72, 69, 75, 95, 70, 76, 65, 71, 83, 40, 72, 69, 75, 80, 111, 105, 110, 116, 101, 114, 77, 97, 114, 107, 101, 114, 41, 44, 10, 32, 32, 32, 32, 32, 32, 32, 32, 72, 86, 95, 70, 69, 84, 67, 72, 95, 73, 83, 83, 84, 79, 82, 69, 44, 32, 38, 80, 76, 95, 115, 118, 95, 117, 110, 100, 101, 102, 44, 10, 32, 32, 32, 32, 32, 32, 32, 32, 72, 69, 75, 95, 72, 65, 83, 72, 40, 72, 69, 75, 80, 111, 105, 110, 116, 101, 114, 77, 97, 114, 107, 101, 114, 41, 41, 59, 10, 32, 32, 32, 32, 32, 40, 118, 111, 105, 100, 41, 32, 104, 118, 95, 115, 116, 111, 114, 101, 40, 105, 115, 97, 95, 104, 97, 115, 104, 44, 32, 34, 85, 78, 73, 86, 69, 82, 83, 65, 76, 34, 44, 32, 57, 44, 32, 38, 80, 76, 95, 115, 118, 95, 117, 110, 100, 101, 102, 44, 32, 48, 41, 59, 10, 10, 32, 32, 32, 32, 32, 83, 118, 82, 69, 65, 68, 79, 78, 76, 89, 95, 111, 110, 40, 105, 115, 97, 95, 104, 97, 115, 104, 41, 59, 10, 10, 32, 32, 32, 32, 32, 115, 116, 114, 117, 99, 116, 80, 111, 105, 110, 116, 101, 114, 77, 97, 114, 107, 101, 114, 45, 62, 65, 86, 80, 111, 105, 110, 116, 101, 114, 77, 97, 114, 107, 101, 114, 32, 61, 32, 105, 115, 97, 95, 104, 97, 115, 104, 59, 10, 32, 32, 32, 32, 125, 10, 10, 32, 32, 32, 32, 114, 101, 116, 117, 114, 110, 32, 65, 86, 80, 111, 105, 110, 116, 101, 114, 77, 97, 114, 107, 101, 114, 59, 10, 125, 10, 10]\n"
     ]
    }
   ],
   "source": [
    "code_tokens = tokenizer.tokenize(sample_text)\n",
    "print(code_tokens)\n",
    "\n",
    "code_ids = tokenizer.convert_tokens_to_ids(code_tokens)\n",
    "print(code_ids)\n",
    "\n",
    "# detokenized_string = tokenizer.decode(code_ids)\n",
    "# print(detokenized_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_code = []\n",
    "for code in input_csv['code']:\n",
    "    code_tokens = tokenizer.tokenize(code)\n",
    "    code_ids = tokenizer.convert_tokens_to_ids(code_tokens)\n",
    "    tokenized_code.append(code_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2182.5478517224437\n"
     ]
    }
   ],
   "source": [
    "# print average length of the sublists in tokenized_code\n",
    "\n",
    "print(np.mean([len(x) for x in tokenized_code]))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the array: (18317, 2048)\n"
     ]
    }
   ],
   "source": [
    "processed_tokenized_code = []\n",
    "\n",
    "# Define the maximum length threshold\n",
    "max_length_threshold = 2048\n",
    "\n",
    "for sublist in tokenized_code:\n",
    "    if len(sublist) < max_length_threshold:\n",
    "        # Pad the sublist with zeros if its length is less than the threshold\n",
    "        padded_sublist = sublist + [0] * (max_length_threshold - len(sublist))\n",
    "        processed_tokenized_code.append(padded_sublist)\n",
    "    else:\n",
    "        # Take the first 1024 elements of the sublist if its length exceeds the threshold\n",
    "        truncated_sublist = sublist[:max_length_threshold]\n",
    "        processed_tokenized_code.append(truncated_sublist)\n",
    "\n",
    "# Convert the processed nested list to a NumPy array\n",
    "tokenized_code_array = np.array(processed_tokenized_code)\n",
    "\n",
    "# Check the shape of the array\n",
    "print(\"Shape of the array:\", tokenized_code_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 32 102 111 ...   0   0   0]\n"
     ]
    }
   ],
   "source": [
    "print(tokenized_code_array[18316])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18317,)\n"
     ]
    }
   ],
   "source": [
    "label = input_csv['Label']\n",
    "print(label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[32, 80, 101, 114, 108, 95, 109, 114, 111, 95,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[32, 104, 97, 110, 100, 108, 101, 80, 82, 69, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[32, 71, 101, 116, 73, 110, 101, 116, 65, 100,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[32, 100, 111, 95, 114, 101, 100, 105, 114, 10...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[32, 103, 102, 95, 97, 102, 95, 110, 101, 119,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               token  label\n",
       "0  [32, 80, 101, 114, 108, 95, 109, 114, 111, 95,...      1\n",
       "1  [32, 104, 97, 110, 100, 108, 101, 80, 82, 69, ...      1\n",
       "2  [32, 71, 101, 116, 73, 110, 101, 116, 65, 100,...      1\n",
       "3  [32, 100, 111, 95, 114, 101, 100, 105, 114, 10...      1\n",
       "4  [32, 103, 102, 95, 97, 102, 95, 110, 101, 119,...      1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'token': tokenized_code_array.tolist(), 'label': label})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output_csv = df.to_csv('output.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(np.array(df['token'].tolist()), np.array(df['label']), test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14653, 2048)\n",
      "(3664, 2048)\n",
      "(14653,)\n",
      "(3664,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_train.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([14653, 2048])\n",
      "torch.Size([14653])\n",
      "torch.Size([3664, 2048])\n",
      "torch.Size([3664])\n"
     ]
    }
   ],
   "source": [
    "x_train = torch.tensor(X_train, dtype=torch.float32, device=device)\n",
    "y_train = torch.tensor(Y_train, dtype=torch.float32, device=device)\n",
    "\n",
    "x_test = torch.tensor(X_test, dtype=torch.float32, device=device)\n",
    "y_test = torch.tensor(Y_test, dtype=torch.float32, device=device)\n",
    "\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "BinaryClassifier(\n",
      "  (fc1): Linear(in_features=2048, out_features=512, bias=True)\n",
      "  (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
      "  (fc3): Linear(in_features=256, out_features=128, bias=True)\n",
      "  (fc4): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (fc5): Linear(in_features=64, out_features=32, bias=True)\n",
      "  (fc6): Linear(in_features=32, out_features=16, bias=True)\n",
      "  (fc7): Linear(in_features=16, out_features=8, bias=True)\n",
      "  (fc8): Linear(in_features=8, out_features=1, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      "  (dropout): Dropout(p=0.3, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Model Architecture\n",
    "import torch.nn as nn\n",
    "\n",
    "class BinaryClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BinaryClassifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(2048, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, 128)\n",
    "        self.fc4 = nn.Linear(128, 64)\n",
    "        self.fc5 = nn.Linear(64, 32)\n",
    "        self.fc6 = nn.Linear(32, 16)\n",
    "        self.fc7 = nn.Linear(16, 8)\n",
    "        self.fc8 = nn.Linear(8,1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.dropout = nn.Dropout(p=0.3)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = torch.relu(self.fc3(x))\n",
    "        x = self.dropout(x)\n",
    "        x = torch.relu(self.fc4(x))\n",
    "        x = self.dropout(x)\n",
    "        x = torch.relu(self.fc5(x))\n",
    "        x = self.dropout(x)\n",
    "        x = torch.relu(self.fc6(x))\n",
    "        x = torch.relu(self.fc7(x))\n",
    "        x = self.sigmoid(self.fc8(x))\n",
    "        return x\n",
    "\n",
    "print(torch.cuda.is_available())\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = BinaryClassifier().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()  # Binary Cross Entropy Loss\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0004)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=================================================================\n",
       "Layer (type:depth-idx)                   Param #\n",
       "=================================================================\n",
       "BinaryClassifier                         --\n",
       "├─Linear: 1-1                            1,049,088\n",
       "├─Linear: 1-2                            131,328\n",
       "├─Linear: 1-3                            32,896\n",
       "├─Linear: 1-4                            8,256\n",
       "├─Linear: 1-5                            2,080\n",
       "├─Linear: 1-6                            528\n",
       "├─Linear: 1-7                            136\n",
       "├─Linear: 1-8                            9\n",
       "├─Sigmoid: 1-9                           --\n",
       "├─Dropout: 1-10                          --\n",
       "=================================================================\n",
       "Total params: 1,224,321\n",
       "Trainable params: 1,224,321\n",
       "Non-trainable params: 0\n",
       "================================================================="
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "summary(BinaryClassifier()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.6895370186118828\n",
      "Epoch 2, Loss: 0.6755272424037946\n",
      "Epoch 3, Loss: 0.6725538339481937\n",
      "Epoch 4, Loss: 0.6712608930172173\n",
      "Epoch 5, Loss: 0.6757961715353211\n",
      "Epoch 6, Loss: 0.6775459496725531\n",
      "Epoch 7, Loss: 0.6811591077938911\n",
      "Epoch 8, Loss: 0.6873864416394964\n",
      "Epoch 9, Loss: 0.6809612112473179\n",
      "Epoch 10, Loss: 0.681331375906559\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "# Define loss function and optimizer\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "epochs = 10\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for inputs, targets in zip(x_train, y_train):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets.unsqueeze(0))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Print statistics\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    # Print average loss for the epoch\n",
    "    print(f\"Epoch {epoch+1}, Loss: {running_loss / len(x_train)}\")\n",
    "\n",
    "print('Finished Training')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "predicted = model(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5750],\n",
      "        [0.5717],\n",
      "        [0.5665],\n",
      "        ...,\n",
      "        [0.5811],\n",
      "        [0.4377],\n",
      "        [0.4377]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6261\n",
      "Precision: 0.5956\n",
      "Recall: 0.7053\n",
      "F1 Score: 0.6458\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Convert the predicted values to binary\n",
    "predicted = (predicted > 0.5).float()\n",
    "\n",
    "# Calculate the evaluation metrics\n",
    "accuracy = accuracy_score(y_test.cpu(), predicted.cpu())\n",
    "precision = precision_score(y_test.cpu(), predicted.cpu())\n",
    "recall = recall_score(y_test.cpu(), predicted.cpu())\n",
    "f1 = f1_score(y_test.cpu(), predicted.cpu())\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "huggingface",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
